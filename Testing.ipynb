{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ec62cfb-49e4-470f-8065-33ba87d988da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2c45e66-4287-494c-bcf7-a4ce667e8071",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\konab\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\konab\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0528b3c-eada-46d3-8cd9-41a9b82e1ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = joblib.load('C:/Users/konab/Downloads/CP NEW/CP NEW/tfidf_vectorizer.joblib')\n",
    "model = joblib.load('C:/Users/konab/Downloads/CP NEW/CP NEW/news_classifier.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a9d1ad4-4f44-48e5-9b66-2cac8625e1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = str(text).lower()  # Convert to lowercase\n",
    "    text = re.sub(f'[{string.punctuation}]', '', text)  # Remove punctuation\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = text.split()\n",
    "    words = [word for word in words if word not in stop_words]  # Remove stopwords\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]  # Lemmatization\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c06f3d7a-3e6c-45ef-9bd5-27ea15292194",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_news(text):\n",
    "    cleaned_text = clean_text(text)  # Clean the text\n",
    "    transformed_text = vectorizer.transform([cleaned_text])  # Convert to TF-IDF\n",
    "    prediction = model.predict(transformed_text)  # Get prediction\n",
    "    return \"FAKE NEWS\" if prediction[0] == 0 else \"REAL NEWS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4f7fe6-d97d-41ad-a3af-80fa7480db27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: REAL NEWS\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "60933a85-0593-4e58-af36-8639a8cd3237",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install textblob\n",
    "from textblob import TextBlob\n",
    "import spacy  # Import SpaCy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c1b7617c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install spacy\n",
    "#!python -m spacy download en_core_web_sm\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "58081ce0-3e5a-4945-8fb4-594c9c037a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Statement\n",
      "Prediction: REAL NEWS\n",
      "[('UNITED NATIONS', 'ORG'), ('Reuters', 'ORG'), ('U.S.', 'GPE'), ('Donald Trump', 'PERSON'), ('the United Nations', 'ORG'), ('first', 'ORDINAL'), ('Monday', 'DATE'), ('U.N.', 'ORG'), ('U.N. General Assembly', 'ORG'), ('Tuesday', 'DATE'), ('Trump', 'ORG'), ('the United Nations', 'ORG'), ('recent years', 'DATE'), ('the United Nations', 'ORG'), ('the United Nations', 'ORG'), ('140 percent', 'PERCENT'), ('2000,â€\\x9d', 'CARDINAL'), ('Trump', 'ORG'), ('â€œThe United Nations', 'ORG'), ('Trump', 'PERSON'), ('â€œI am', 'PERSON'), ('the United Nations', 'ORG'), ('Trump', 'PERSON'), ('first', 'ORDINAL'), ('U.N.', 'ORG'), ('New York', 'GPE'), ('January', 'DATE'), ('Trump', 'ORG'), ('just four minutes', 'TIME'), ('Some 128', 'CARDINAL'), ('10', 'CARDINAL'), ('U.N.', 'ORG'), ('Antonio Guterres', 'PERSON'), ('reform.â€\\x9d U.N. Security Council', 'ORG'), ('Russia', 'GPE'), ('China', 'GPE'), ('Trump', 'PERSON'), ('2016', 'DATE'), ('the United States', 'GPE'), ('the United Nations', 'ORG'), ('Monday', 'DATE'), ('thatâ€', 'CARDINAL'), ('financially.â€\\x9d', 'ORG'), ('The United States', 'GPE'), ('U.N.', 'ORG'), ('22 percent', 'PERCENT'), ('$5.4 billion', 'MONEY'), ('28.5 percent', 'PERCENT'), ('$7.3 billion', 'MONEY'), ('193', 'CARDINAL'), ('General Assembly', 'ORG'), ('Guterres', 'PERSON'), ('January', 'DATE'), ('efficient.â€\\x9d', 'NORP'), ('U.N', 'ORG'), ('night', 'TIME'), ('a 21st century', 'DATE'), ('U.N.', 'ORG'), ('Guterres', 'PERSON'), ('Trump', 'ORG'), ('The United States', 'GPE'), ('U.N.', 'ORG'), ('annual', 'DATE'), ('Security Council', 'ORG'), ('The United States', 'GPE'), ('Britain', 'GPE'), ('France', 'GPE'), ('Russia', 'GPE'), ('China', 'GPE'), ('Sunday', 'DATE'), ('night', 'TIME'), ('U.S.', 'GPE'), ('State', 'ORG'), ('Rex Tillerson', 'PERSON'), ('U.N.', 'ORG'), ('Filippo Grandi', 'PERSON'), ('U.N.', 'ORG'), ('the United States', 'GPE'), ('Grandi', 'PERSON'), ('no.â€\\x9d â€œU.S.', 'PERSON'), ('Grandi', 'PERSON')]\n"
     ]
    }
   ],
   "source": [
    "a=input()\n",
    "blob = TextBlob(a)\n",
    "doc = nlp(a)\n",
    "s = blob.sentiment.polarity\n",
    "if(s>0):\n",
    "    print(\"Positive Statement\")\n",
    "elif(s<0):\n",
    "    print(\"Negative Statement\")\n",
    "else:\n",
    "    print(\"Neutral Statement\")\n",
    "print(\"Prediction:\", predict_news(a))\n",
    "entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "print(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706069a1-c090-4a52-adb0-fa93d45d14ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33dd4c35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
